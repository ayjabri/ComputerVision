{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue-Bold;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 Verdana-Bold;
\f3\fnil\fcharset0 Verdana;\f4\fswiss\fcharset0 Helvetica;\f5\fmodern\fcharset0 CourierNewPSMT;
\f6\fnil\fcharset0 HelveticaNeue-UltraLight;\f7\fnil\fcharset0 Verdana-Italic;\f8\fnil\fcharset0 AppleSymbols;
\f9\froman\fcharset0 Palatino-Bold;}
{\colortbl;\red255\green255\blue255;\red55\green55\blue55;\red255\green255\blue255;\red26\green26\blue26;
\red251\green0\blue7;\red37\green37\blue37;\red0\green0\blue0;\red0\green0\blue255;\red12\green96\blue165;
\red81\green81\blue81;\red83\green83\blue83;\red244\green244\blue244;\red38\green38\blue38;\red237\green237\blue237;
\red252\green251\blue251;}
{\*\expandedcolortbl;;\cssrgb\c27843\c27843\c27843;\cssrgb\c100000\c100000\c100000;\cssrgb\c13333\c13333\c13333;
\cssrgb\c100000\c0\c0;\cssrgb\c19216\c19216\c19216;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c100000;\cssrgb\c0\c45882\c70588;
\cssrgb\c39216\c39216\c39216;\cssrgb\c40000\c40000\c40000;\cssrgb\c96471\c96471\c96471;\cssrgb\c20000\c20000\c20000;\cssrgb\c94510\c94510\c94510;
\csgenericrgb\c98824\c98431\c98431;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid2\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl504\partightenfactor0

\f0\b\fs36 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Machine Learning\
\pard\pardeftab720\sl414\partightenfactor0

\f1\b0\fs32 \cf4 \strokec4 \
\pard\pardeftab720\sl537\sa200\partightenfactor0

\f2\b\fs38\fsmilli19200 \cf5 \strokec5 INSTRUCTIONS
\f0 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f3\b0\fs32 \cf7 \cb3 \strokec7 There are three parts to this assignment. Please read all sections of\'a0the\'a0instructions carefully.
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f2\b \cf7 \cb3 \strokec7 I.
\f3\b0 \'a0Perceptron Learning Algorithm (50 points)
\f1 \cf6 \cb1 \strokec6 \uc0\u8232 
\f2\b \cf7 \cb3 \strokec7 II.
\f3\b0 \'a0Linear Regression (50 points)
\f1 \cf6 \cb1 \strokec6 \uc0\u8232 
\f2\b \cf7 \cb3 \strokec7 III.
\f3\b0 \'a0Classification (100 points)
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f3 \cf7 \cb3 \strokec7 You are allowed to\'a0use Python packages to help you solve the problems and plot any results for reference, including\'a0
\f2\b numpy, scipy, pandas
\f3\b0 \'a0and\'a0
\f2\b scikit-learn
\f3\b0 . For optional problems, you may find\'a0
\f2\b matplotlib
\f3\b0 \'a0package useful.
\f1 \cf6 \cb1 \strokec6 \

\f3 \cf7 \cb3 \strokec7 However, please do NOT\'a0submit any code using Tkinter, matplotlib, seaborn, or any other plotting library.\'a0
\f2\b This will make your code fail on Vocareum.
\f3\b0 \'a0This is because\'a0Vocareum does not have a display, so you can't actually produce a pop-up window with your plots, the way you can on your local machine.
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf5 \cb3 \strokec7 Bonus Points:
\f3\b0 \cf7 \'a0
\f4 \cb1 \

\f2\b \cf5 \cb3 Submitting project 3 before 04/12/2020, 23:30 UTC is eligible for bonus points (we count grades on your latest submission). Due to edX policy, all assignment grades are capped at 100%.
\f4\b0 \cf7 \cb1 \
\pard\pardeftab720\sl512\sa453\partightenfactor0

\f1 \cf6 \strokec6 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf8 \cb3 \strokec7 The assignment's final due date is 5/17/2020, 23:30 UTC.\'a0
\f4\b0 \cf7 \cb1 \
\pard\pardeftab720\sl537\sa200\partightenfactor0

\f2\b\fs38\fsmilli19200 \cf7 \cb3 I. Perceptron Learning Algorithm
\f0 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl440\partightenfactor0

\f4\b0\fs32 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 In this question, you will implement the perceptron learning algorithm ("PLA") for a linearly separable dataset. In your starter code, you will find\'a0
\f5 \cf8 input1.csv
\f3 \cf7 , containing a series of data points. Each point is a comma-separated ordered triple, representing\'a0
\f2\b feature_1
\f3\b0 ,\'a0
\f2\b feature_2
\f3\b0 , and the\'a0
\f2\b label
\f3\b0 \'a0for the point. You can think of the values of the features as the x- and y-coordinates of each point. The label takes on a value of positive or negative one. You can think of the label as separating the points into two categories.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 Implement your PLA in a file called\'a0
\f5 \cf8 problem1.py
\f3 \cf7 , which will be executed like so:
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f5 \cf8 \cb3 $ python3 problem1.py input1.csv output1.csv
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl440\partightenfactor0

\f4 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 This should generate an output file called\'a0
\f5 \cf8 output1.csv
\f3 \cf7 . With each iteration of your PLA (each time we go through all examples), your program must print a new line to the output file, containing a comma-separated list of the weights\'a0
\f2\b w_1
\f3\b0 ,\'a0
\f2\b w_2
\f3\b0 , and\'a0
\f2\b b
\f3\b0 \'a0in that order. Upon\'a0convergence, your program will stop, and the final values of\'a0w_1, w_2, and b will be printed to the output file (see\'a0{\field{\*\fldinst{HYPERLINK "https://studio.edx.org/asset-v1:ColumbiaX+CSMM.101x+1T2017+type@asset+block@output1.csv"}}{\fldrslt 
\f2\b \cf9 example}}). This defines\'a0the\'a0
\f2\b decision boundary
\f3\b0 \'a0that your PLA has computed for the given dataset.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 Note: When implementing your PLA, in case of tie (sum of w_jx_ij = 0), please follow the lecture note and classify the datapoint as -1.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf5 \cb3 What To Submit
\f3\b0 \cf7 .\'a0
\f5 \cf8 problem1.py
\f3 \cf7 ,\'a0which should behave as specified above. Before you submit, the\'a0
\f2\b RUN
\f3\b0 \'a0button on Vocareum should help you determine whether or not your program executes correctly on the platform.
\f4 \cb1 \
\pard\pardeftab720\sl448\qc\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf7 \cb3 Optional (0 pts)
\f3\b0 . To visualize the progress and final result of your program, you can use\'a0
\f2\b matplotlib
\f3\b0 \'a0to output an image for each iteration of your algorithm. For instance, you can plot each category with a different color, and plot the decision boundary with its equation. An example is shown above for reference.
\f4 \cb1 \
\pard\pardeftab720\sl672\partightenfactor0

\f0\b\fs48 \cf10 \cb3 \strokec10 Machine Learning #1 (AI.t) (External resource)
\f1\b0\fs32 \cf4 \strokec4 \'a0
\f6 \cf11 \strokec11 (50.0 / 50.0 points)\
\pard\pardeftab720\sl380\partightenfactor0

\f1\fs28 \cf4 \cb12 \strokec4 Your email address will be used to identify your submission entry.\cb1 \
\pard\pardeftab720\sl414\partightenfactor0

\f0\b\fs26 \cf13 \cb14 \strokec13 \shad\shadx0\shady-20\shadr0\shado255 \shadc15 Go To Question #1\'a0
\f1\b0\fs28 \cf4 \cb1 \strokec4 \shad0 \
\pard\pardeftab720\sl537\sa200\partightenfactor0

\f2\b\fs38\fsmilli19200 \cf7 \cb3 \strokec7 II.\'a0Linear Regression
\f0 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl440\partightenfactor0

\f4\b0\fs32 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 In this problem, you will work on linear regression with multiple features using gradient descent.\'a0In your starter code, you will find
\f5 \'a0\cf8 input2.csv
\f3 \cf7 , containing a series of data points. Each point is a comma-separated ordered triple, representing\'a0
\f2\b age
\f3\b0 ,\'a0
\f2\b weight
\f3\b0 , and\'a0
\f2\b height
\f3\b0 \'a0(derived from CDC growth charts data).
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf7 \cb3 Data Preparation and Normalization
\f3\b0 . Once you load your dataset, explore the content to identify each feature. Remember to add the vector 1 (intercept) ahead of your data matrix.\'a0You will notice that the\'a0
\f2\b features
\f3\b0 \'a0are not on the same scale. They represent age (years), and weight (kilograms). What is\'a0the mean and standard deviation of each feature? The last column is the\'a0
\f2\b label
\f3\b0 , and represents the height (meters).\'a0
\f2\b Scale
\f3\b0 \'a0each feature (i.e. age and weight) by its (population) standard deviation, and set its mean to zero. (Can you see why this will help?) You do not need to scale the intercept. (Can you see why this is unnecessary?)
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 For each feature\'a0
\f7\i x
\f3\i0 \'a0(a column in your data matrix), use the following formula for scaling:
\f4 \cb1 \
\pard\pardeftab720\sl448\sa453\qc\partightenfactor0

\f3 \cf6 \strokec6 
\f1 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f2\b \cf6 \cb3 Gradient Descent
\f3\b0 . Implement gradient descent to find a regression model. Initialize your \uc0\u946 \'92s to zero. Recall the empirical risk and gradient descent rule as follows:
\f1 \cb1 \
\pard\pardeftab720\sl448\sa453\qc\partightenfactor0

\f3 \cf6 \pard\pardeftab720\sl448\sa453\qc\partightenfactor0

\f1 \cf6 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f3 \cf6 \cb3 Run the gradient descent algorithm using\'a0the following\'a0
\f2\b learning rates
\f3\b0 :\'a0\uc0\u945  
\f8 \uc0\u8712 
\f3  \{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10\}.\'a0For each value of\'a0\uc0\u945 , run the algorithm for exactly\'a0
\f2\b 100 iterations
\f3\b0 .\'a0Compare the convergence rate when \uc0\u945  is small versus large. What is the ideal learning rate to obtain an accurate model? In addition to the nine learning rates\'a0above, come up with\'a0
\f2\b your own choice
\f3\b0 \'a0of\'a0value for the learning rate. Then, using this new learning rate, run the algorithm for your own choice of number of iterations.
\f1 \cb1 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 \strokec7 Implement your gradient descent\'a0in a file called\'a0
\f5 \cf8 problem2.py
\f3 \cf7 , which will be executed like so:
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f5 \cf8 \cb3 $ python3 problem2.py input2.csv output2.csv
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl440\partightenfactor0

\f4 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 This should generate an output file called\'a0
\f5 \cf8 output2.csv
\f3 \cf7 . There are\'a0
\f2\b ten cases
\f3\b0 \'a0in total, nine with the specified learning rates (and 100 iterations), and one with your own choice of learning rate (and your choice of number of iterations). After\'a0each of these ten runs,\'a0your program must print a new line to the output file, containing a comma-separated list of\'a0
\f2\b alpha
\f3\b0 ,\'a0
\f2\b number_of_iterations
\f3\b0 ,\'a0
\f2\b b_0
\f3\b0 ,\'a0
\f2\b b_age
\f3\b0 , and\'a0
\f2\b b_weight
\f3\b0 \'a0in that order (see\'a0{\field{\*\fldinst{HYPERLINK "https://studio.edx.org/asset-v1:ColumbiaX+CSMM.101x+1T2017+type@asset+block@output2.csv"}}{\fldrslt 
\f2\b \cf9 example}}), please do not round you your numbers. These represent the regression models\'a0that your gradient descents have computed for the given dataset.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf7 \cb3 For the output, please follow the exact format, with no extra commas, change in upper/lower case etc.
\f3\b0 \'a0Extra unnecessary commas may make the automated script fail and result in you losing points.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf5 \cb3 What To Submit
\f3\b0 \cf7 .\'a0
\f5 \cf8 problem2.py
\f3 \cf7 ,\'a0which should behave as specified above. Before you submit,\'a0the\'a0
\f9\b RUN
\f3\b0 \'a0button on Vocareum should help you determine whether or not your program executes correctly on the platform.
\f4 \cb1 \
\pard\pardeftab720\sl448\qc\partightenfactor0

\f3 \cf7 \pard\pardeftab720\sl448\qc\partightenfactor0

\f4 \cf7 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f2\b \cf6 \cb3 \strokec6 Optional (0 pts)
\f3\b0 . To visualize the result of each case of gradient descent, you can use\'a0
\f2\b matplotlib
\f3\b0 \'a0to output an image for each linear regression model in three-dimensional space. For instance, you can plot each feature on the xy-plane, and plot the regression equation as a plane in xyz-space. An example is shown above for reference.
\f1 \cb1 \
\pard\pardeftab720\sl672\partightenfactor0

\f0\b\fs48 \cf10 \cb3 \strokec10 Machine Learning #2 (AI.t) (External resource)
\f1\b0\fs32 \cf4 \strokec4 \'a0
\f6 \cf11 \strokec11 (50.0 / 50.0 points)\
\pard\pardeftab720\sl380\partightenfactor0

\f1\fs28 \cf4 \cb12 \strokec4 Your email address will be used to identify your submission entry.\cb1 \
\pard\pardeftab720\sl414\partightenfactor0

\f0\b\fs26 \cf13 \cb14 \strokec13 \shad\shadx0\shady-20\shadr0\shado255 \shadc15 Go To Question #2\'a0
\f1\b0\fs28 \cf4 \cb1 \strokec4 \shad0 \
\pard\pardeftab720\sl537\sa200\partightenfactor0

\f2\b\fs38\fsmilli19200 \cf7 \cb3 \strokec7 III.\'a0Classification
\f0 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl440\partightenfactor0

\f4\b0\fs32 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 In this problem you will use the support vector classifiers in the\'a0
\f2\b sklearn
\f3\b0 \'a0package to learn a classification model for a chessboard-like dataset.\'a0In your starter code, you will find\'a0
\f5 \cf8 input3.csv
\f3 \cf7 , containing a series of data points.\'a0Open the dataset in python. Make a scatter plot of the dataset showing the two classes with two different patterns.
\f4 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf7 \
\pard\pardeftab720\sl448\partightenfactor0

\f3 \cf7 \cb3 Use SVM with different kernels to build a classifier. Make sure you split your data into\'a0
\f2\b training
\f3\b0 \'a0(60%) and\'a0
\f2\b testing
\f3\b0 \'a0(40%). Also make sure you use\'a0
\f2\b stratified sampling
\f3\b0 \'a0(i.e. same ratio of positive to negative in both the training and testing datasets). Use\'a0
\f2\b cross validation
\f3\b0 \'a0(with the number of folds\'a0
\f7\i k
\f3\i0 \'a0=\'a05) instead of a validation set. You do not need to\'a0scale/normalize the data for this question. Train-test splitting and cross validation functionalities are all readily available in sklearn.
\f4 \cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sl448\sa226\partightenfactor0
\ls1\ilvl1
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 SVM with Linear Kernel
\f3\b0 . Observe\'a0the performance of the SVM with\'a0linear kernel. Search for a good setting of parameters to obtain high classification accuracy. Specifically, try values of C =\'a0[0.1, 0.5, 1, 5, 10, 50, 100]. Read about\'a0
\f9\b sklearn.grid_search
\f3\b0 \'a0and how this can help you accomplish this task. After locating the optimal parameter value by using the training data, record the corresponding\'a0
\f9\b best score
\f3\b0 \'a0(training data accuracy) achieved. Then apply the testing data to the model, and record the actual\'a0
\f9\b test score
\f3\b0 . Both scores will be a number between zero and one.
\f1 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls2\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 SVM with Polynomial
\f2 \'a0Kernel
\f3\b0 . (Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 T\strokec6 ry values of C =\'a0[0.1, 1, 3], degree = [4, 5, 6], and gamma = [0.1, 0.5].
\f1 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls3\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 SVM with RBF Kernel
\f3\b0 . (Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 \strokec6 T\cf7 \strokec7 ry values of\'a0C = [0.1, 0.5, 1, 5, 10, 50, 100] and\'a0\cf6 \strokec6 gamma = [0.1, 0.5, 1, 3, 6, 10].
\f1 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls4\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 Logistic Regression
\f3\b0 .\'a0(Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 \strokec6 T\cf7 \strokec7 ry values of C = [0.1, 0.5, 1, 5, 10, 50, 100].
\f1 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls5\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 k-Nearest Neighbors
\f3\b0 .\'a0(Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 \strokec6 Try values of n_neighbors = [1, 2, 3, ..., 50] and leaf_size = [5, 10, 15, ..., 60].
\f1 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls6\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 Decision Trees
\f3\b0 .\'a0(Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 \strokec6 T\cf7 \strokec7 ry values of max_depth = [1, 2, 3, ..., 50] and min_samples_split = [2, 3, 4, ..., 10].
\f1 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls7\ilvl0
\f9\b \cf7 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 Random Forest
\f3\b0 .\'a0(Similar to above).\cb1 \uc0\u8232 \cf6 \cb3 \strokec6 Try values of max_depth = [1, 2, 3, ..., 50] and min_samples_split = [2, 3, 4, ..., 10].
\f1 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0

\f4 \cf7 \strokec7 \
\pard\pardeftab720\sl448\partightenfactor0

\f2\b \cf5 \cb3 What To Submit
\f3\b0 \cf7 .\'a0
\f5 \cf8 output3.csv\cf7 \'a0
\f3 (see\'a0{\field{\*\fldinst{HYPERLINK "https://studio.edx.org/asset-v1:ColumbiaX+CSMM.101x+1T2017+type@asset+block@output3.csv"}}{\fldrslt 
\f2\b \cf9 example}}).\'a0
\f2\b Please follow the exact format, with no extra commas, change in upper/lower case etc.
\f3\b0 \'a0Extra unnecessary commas may make the automated script fail and result in you losing points. There is no need to submit your actual program. The file\'a0should contain an entry for each of the seven methods used. For each method, print a comma-separated list as shown in the example, including the\'a0
\f2\b method name
\f3\b0 ,\'a0
\f2\b best score
\f3\b0 , and\'a0
\f2\b test score
\f3\b0 , expressed with as many decimal places as you please. There may be more than one way to implement a certain method, and we will allow\'a0for small variations in output you may encounter\'a0depending on the specific functions you decide to use.
\f4 \cb1 \
\pard\pardeftab720\sl448\qc\partightenfactor0

\f3 \cf7 \pard\pardeftab720\sl448\qc\partightenfactor0

\f4 \cf7 \
\pard\pardeftab720\sl448\sa453\partightenfactor0

\f2\b \cf7 \cb3 Optional (0 pts)
\f3\b0 . To visualize the result of each case of classification method, you can use\'a0
\f2\b matplotlib
\f3\b0 \'a0to output an image containing the data points and boundaries of each method. An\'a0example output showing the result of SVM with RBF kernel is shown\'a0above for reference.
\f1 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sl537\sa200\partightenfactor0

\f2\b\fs38\fsmilli19200 \cf7 \cb3 \strokec7 BEFORE YOU\'a0SUBMIT
\f0 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl448\sa226\partightenfactor0
\ls8\ilvl0
\f2\fs32 \cf5 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 Make sure
\f3\b0 \cf7 \strokec7 \'a0your code\'a0executes without fail on Vocareum. In particular, make sure you name your file correctly according to the instructions\'a0specified above, especially regarding different Python versions.
\f1 \cf6 \cb1 \strokec6 \
\ls8\ilvl0
\f2\b \cf5 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec7 Bonus Credits for Early Submission:\'a0
\f3\b0 \cf7 \'a0If you finish this project assignment before
\f2\b \cf8 \'a0April\'a012th 2020 23:30 UTC\cf7 \'a0
\f3\b0 \'a0you will get extra credits for this homework as a bonus (we count grades on your latest submission). Due to edX policy, all assignment grades are capped at 100%.
\f1 \cf6 \cb1 \strokec6 \
\ls8\ilvl0
\f2\b \cf5 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 You have an unlimited number of\'a0submissions
\f3\b0 \cf7 \strokec7 .
\f1 \cf6 \cb1 \strokec6 \
}