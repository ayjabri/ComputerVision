{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Kannanda_MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayjabri/ImageClassification/blob/master/Kannanda_MNIST_MixedNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy2U3JEHb3w2",
        "colab_type": "text"
      },
      "source": [
        "# 1. Reading data\n",
        "\n",
        "Start by importing pandas library and reading test,train and the Dig files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "NowQ4c6Sb3w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVNdhNFvb3w7",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Import csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iZCgGvOub3w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "dig_MNIST = pd.read_csv('Dig-MNIST.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1W416jfhb3xG",
        "colab_type": "code",
        "outputId": "2b9736cc-c817-40f7-edcf-ebc25fe84d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df.label),len(test_df.id)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc9kYh6Mb3xK",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Generate X and Y from training csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mPonXgI3b3xL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BxXXG4Ib3xO",
        "colab_type": "text"
      },
      "source": [
        "For 'x': \n",
        "* Drop the label column and extract the 784 reamining columns\n",
        "* Convert the numpy array to float tensor \n",
        "* Reshape the tensor to (60000,28,28) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hlsn2Nl-b3xP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "088e5dab-6ec7-46cd-d697-3055e6977309"
      },
      "source": [
        "x = torch.from_numpy(train_df.drop(labels=['label'],axis=1).values).float()\n",
        "x = x.view(x.size(0),-1,28,28)\n",
        "\n",
        "y = torch.from_numpy(train_df.label.values).long()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 1, 28, 28]), torch.Size([60000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuQAUVtSb3xS",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VUR_1ez1b3xT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "60f2dc62-ddce-41c4-bffd-86e128931a24"
      },
      "source": [
        "import torchvision as tv\n",
        "import matplotlib.pyplot as plt\n",
        "imgs = tv.utils.make_grid(x[:100],nrow=10,padding=1,pad_value=255)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.imshow(imgs.permute(1,2,0),cmap='Greys')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efbbf51d4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyEAAAMbCAYAAABaD5o4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZITe7ZQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x1008 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMtAcakb3xW",
        "colab_type": "text"
      },
      "source": [
        "# 2. Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLw9fcYb3xX",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Write a custom Dataset that allows image transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QxcXlqRRb3xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y1feKvNDb3xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self,x,y,transform=None):\n",
        "        self.data = x\n",
        "        self.target = y\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "    def __getitem__(self,idx):\n",
        "        label= self.target[idx]\n",
        "        img = self.data[idx]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ILoNyHb3xc",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Create the dataset and loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0jBC9CSb3xd",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1. Transforms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2e35najab3xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nj5966hZb3xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = transforms.Compose([transforms.Normalize((0.5,),(0.5,))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9sdWxXJb3xj",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.2. Dataset and DataLoader\n",
        "We create a dataset then we split it 20-80 into training and validating datasets.\n",
        "Then we create two DataLoader: `dl` for training and `dlv` for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-sllhXgab3xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dsm = MyDataset(x,y,transform=tfms)\n",
        "\n",
        "ds,dsv = torch.utils.data.random_split(dsm,[48000,12000]) #split the data\n",
        "dl = DataLoader(ds,batch_size=1000,shuffle=True,pin_memory=True)\n",
        "dlv = DataLoader(dsv, batch_size=1000, shuffle=False,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIU8ByEnb3xm",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.3. Small Dataset and DataLoader to overfit the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gV7QIMjxb3xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampler = torch.utils.data.RandomSampler(ds,num_samples=500,replacement=True)\n",
        "dls = DataLoader(ds,batch_size=100,sampler=sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04q2Troob3xo",
        "colab_type": "text"
      },
      "source": [
        "# 3. Mixed Neural Network (1D,2D):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RhkmT4gcb3xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMwp9Xbcb3xr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zmzuiPYXb3xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,out,kernel):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv1d(28,out,kernel,padding=3,bias=False),\n",
        "                                   nn.BatchNorm1d(out),\n",
        "                                   nn.LeakyReLU(inplace=True),\n",
        "                                   nn.Conv1d(out,out,kernel-2,padding=3,bias=False),\n",
        "                                   nn.BatchNorm1d(out),\n",
        "                                   nn.LeakyReLU(inplace=True),\n",
        "                                   nn.Conv1d(out,out,kernel-2,padding=3,bias=False),\n",
        "                                   nn.BatchNorm1d(out),\n",
        "                                   nn.LeakyReLU(inplace=True)\n",
        "                                   )\n",
        "        self.pool1 = nn.AdaptiveAvgPool1d(1)\n",
        "        self.pool2 = nn.AdaptiveMaxPool1d(1)\n",
        "        self.drop1 = nn.Dropout(p=0.25)\n",
        "        \n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(1,out,kernel,padding=3,bias=False),\n",
        "                                   nn.BatchNorm2d(out),\n",
        "                                   nn.LeakyReLU(inplace=True),\n",
        "                                   nn.Conv2d(out,out,kernel-2,padding=3,bias=False),\n",
        "                                   nn.BatchNorm2d(out),\n",
        "                                   nn.LeakyReLU(inplace=True),\n",
        "                                   nn.Conv2d(out,out,kernel-2,padding=3,bias=False),\n",
        "                                   nn.BatchNorm2d(out),\n",
        "                                   nn.ReLU(inplace=True))\n",
        "        self.pool3 = nn.AdaptiveAvgPool2d(1)\n",
        "        self.pool4 = nn.AdaptiveMaxPool2d(1)\n",
        "        self.drop2 = nn.Dropout(p=0.25)\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Flatten(),\n",
        "                                nn.Linear(out*4,out*2),\n",
        "                                nn.BatchNorm1d(int(out*2)),\n",
        "                                nn.LeakyReLU(inplace=True),\n",
        "                                nn.Dropout(p=0.5),\n",
        "                                nn.Linear(out*2,10))\n",
        "    def forward(self,x):\n",
        "        x1 = x.squeeze(1)\n",
        "        x1 = self.conv1(x1)\n",
        "        p1 = self.pool1(x1)\n",
        "        p2 = self.pool2(x1)\n",
        "        x1 = torch.cat((p1,p2),dim=1)\n",
        "        x1 = self.drop1(x1)\n",
        "        x2 = self.conv2(x)\n",
        "        p3 = self.pool3(x2)\n",
        "        p4 = self.pool4(x2)\n",
        "        x2 = torch.cat((p3,p4),dim=1)\n",
        "        x2 = self.drop2(x2)\n",
        "        x = torch.cat((x1,x2.squeeze(2)),dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Yue6Vnvb3xu",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Runner:\n",
        "\n",
        "The runner is a class that allows me to change output_channels and kernal size to try different combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Dgt2I5W4b3xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Runner():\n",
        "    def __init__(self,out_channels,kernel_size,data,epochs,lr=1e-3):\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.data = data\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "    def run(self):\n",
        "        net = Net(self.out_channels,self.kernel_size).to(device)\n",
        "#         summary = SummaryWriter(comment='filters:{} kernel:{} lr:{}'.format(\n",
        "#             self.out_channels,self.kernel_size,self.lr))\n",
        "#         summary.add_graph(net,img)\n",
        "        l,a = learn(net,self.data,self.epochs,self.lr)\n",
        "        \n",
        "        fig, ax1 = plt.subplots()\n",
        "        color = 'tab:red'\n",
        "        ax1.set_xlabel('lr={} out_channels={} kernel={}'.format(\n",
        "            self.lr,self.out_channels,self.kernel_size))\n",
        "        ax1.set_ylabel('losses', color=color)\n",
        "        ax1.plot(l, color=color)\n",
        "        ax1.tick_params(axis='y', labelcolor=color)\n",
        "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "        color = 'tab:blue'\n",
        "        ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n",
        "        ax2.plot(a, color=color)\n",
        "        ax2.tick_params(axis='y', labelcolor=color)\n",
        "        fig.tight_layout()\n",
        "        return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tlQmVn2b3xw",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Support codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewLDBhXHb3xx",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.1 Get the correct number of predections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DMglNVjYb3xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct_num(predicts,labels):\n",
        "    correct = predicts.softmax(dim=1).argmax(dim=1).eq(labels).sum().item()\n",
        "    accuracy = round(correct/len(labels)*100,3)\n",
        "    return correct,accuracy\n",
        "\n",
        "def GPU(img,label):\n",
        "    if torch.cuda.is_available(): img,label = img.to(device),label.to(device)\n",
        "    return img,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6CPojIlb3xz",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.2 Predict all samples in DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vy7G6dbWb3x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def predict_all(net,dl):\n",
        "    predicts = torch.tensor([])\n",
        "    labels = torch.LongTensor([])\n",
        "    for batch in dl:\n",
        "        img,label = batch\n",
        "        net.cpu()\n",
        "        pred = net(img)\n",
        "        predicts = torch.cat((predicts,pred),dim=0)\n",
        "        labels = torch.cat((labels,label),dim=0)\n",
        "        del img,label # To free memory.very effective when using GPUs\n",
        "    return predicts,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_B8A1lb3x2",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.3 Learn function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v0uDkZJAb3x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn(net,epochs,dl,dv=None,lr=1e-3):\n",
        "    '''\n",
        "    Train the network:\n",
        "        net: CNN\n",
        "        epochs: number of epochs\n",
        "        dl: Training DataLoader\n",
        "        dv: Validation DataLoader\n",
        "        lr: Learning rate (defualt=1e-3)\n",
        "    '''\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
        "    for epoch in range(1,epochs+1):\n",
        "        losses = 0\n",
        "        correct = 0\n",
        "        for batch in dl:\n",
        "            optimizer.zero_grad()\n",
        "            img,label = batch\n",
        "            GPU(img,label)\n",
        "            output = net(img)\n",
        "            loss = loss_fn(output,label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses += loss.item()\n",
        "            c,_ = get_correct_num(output,label)\n",
        "            correct += c\n",
        "            del img,label\n",
        "        accuracy = round(correct/len(dl.sampler)*100,3)\n",
        "        if dv is not None:\n",
        "            lossv = 0\n",
        "            correctv = 0\n",
        "            for valid in dv:\n",
        "                imv,labelv = valid\n",
        "                GPU(imv,labelv)\n",
        "                outputv = net(imv)\n",
        "                lossv += loss_fn(outputv,labelv)\n",
        "                cv,_=get_correct_num(outputv,labelv)\n",
        "                correctv += cv\n",
        "                del imv,labelv\n",
        "            accuracyv = round(correctv/len(dv.sampler)*100,3)\n",
        "\n",
        "            if epoch <=5:    \n",
        "                print('''{:<3}|Loss: train {:10.12f}, valid {:10.12f} |Accuracy: train {:3}%, valid:{:3}%\n",
        "                      '''.format(epoch,losses,lossv,accuracy,accuracyv))\n",
        "            else:\n",
        "                if epoch%10 ==0:\n",
        "                    print('''{:<3}|Loss: train {:10.12f}, valid {:10.12f} |Accuracy: train {:3}%, valid:{:3}%\n",
        "                      '''.format(epoch,losses,lossv,accuracy,accuracyv))\n",
        "        else:\n",
        "            if epoch <=5:    \n",
        "                print('''{:<3}|Loss: train {:10.12f} | Accuracy: train {:3}%\n",
        "                      '''.format(epoch,losses,accuracy))\n",
        "            else:\n",
        "                if epoch%10 ==0:\n",
        "                    print('''{:<3}|Loss: train {:10.12f} | Accuracy: train {:3}%\n",
        "                      '''.format(epoch,losses,accuracy))\n",
        "    return losses,correct\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDNdJSjKb3x5",
        "colab_type": "text"
      },
      "source": [
        "# 4. Run the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4tisUhVb3x6",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. To GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ExGYU5_Ob3x6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65e68b53-7144-4c03-cde7-ab74b38be5ba"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-UYZpLXb3x8",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Create and train the network\n",
        "\n",
        "`Runner_1d(out_channels,kernel_size,data,epochs,lr=1e-3)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTzusPTwb3x9",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.1. Use Runner to create and pre-train the network using the small loader `dls`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5gQmjp2rb3x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "174df006-5e3b-41b9-df68-693f737a374c"
      },
      "source": [
        "r = Runner(64,7,dls,100) \n",
        "net = r.run()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-330149d4ae6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-ea284263610d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#         summary = SummaryWriter(comment='filters:{} kernel:{} lr:{}'.format(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             self.out_channels,self.kernel_size,self.lr))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    196\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFEqWRrvb3yB",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.2. Train the Network with training loader `dl`\n",
        "If you want to train the network on the combined train & Dig_MNIST datasets, then go to 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p_PfcfeIb3yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss,accuracy = learn(net,dl,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fg_rqrl2b3yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l,a = learn(net,dl,15,lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V70m3blUb3yG",
        "colab_type": "text"
      },
      "source": [
        "# 5. Save/Load the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iOaPW3kYb3yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO save the network:\n",
        "# torch.save(net.state_dict(),'KannadaMNIST_100_7.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gFSyM2txb3yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To load the network from saved location, uncomment the below\n",
        "net = Net1D(100,7)\n",
        "net.load_state_dict(torch.load('/kaggle/input/parameters/KannadaMNIST_100_7.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hEAKhLBob3yK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l,a = learn(net.to(device),dl,5,lr=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "YKIcbCO1b3yN",
        "colab_type": "text"
      },
      "source": [
        "# 6. Submit the results\n",
        "## 6.1. Predict Test Set\n",
        "### 6.1.1. Extract X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k88bpWBib3yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "",
        "_uuid": "",
        "trusted": true,
        "id": "Eg77rzZAb3yQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = torch.from_numpy(df_test.drop(labels=['id'],axis=1).values).float()\n",
        "x_test = x_test.view(x_test.size(0),-1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43vPrhoab3yS",
        "colab_type": "text"
      },
      "source": [
        "### 6.1.1. Create Test Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8MWfYvztb3yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dlt = DataLoader(x_test,batch_size=100,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v8-KD_Q7b3yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_submit(net,loader):\n",
        "    with torch.no_grad():\n",
        "        predict = torch.tensor([]).to(device)\n",
        "        for img in loader:\n",
        "            if torch.cuda.is_available(): img=img.to(device)\n",
        "            p=net(img)\n",
        "            predict = torch.cat((predict,p),dim=0)\n",
        "        submit = predict.argmax(dim=1)\n",
        "        return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bnGYT0icb3yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = pred_submit(m,dlt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Hhf1uy9-b3yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samplesubmission = pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')\n",
        "samplesubmission['label']=pd.DataFrame(submit.argmax(dim=1).cpu().int())\n",
        "samplesubmission.to_csv(\"CONV1S.csv\", index=False, header=True)\n",
        "# submit_to_csv('samplesubmission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCKEOIDwb3yf",
        "colab_type": "text"
      },
      "source": [
        "# 7. Dig MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O6MAaSCJb3yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xd = torch.from_numpy(dig_MNIST.drop(['label'],axis=1).values).float()\n",
        "xd = xd.view(xd.size(0),-1,28,28);xd.shape\n",
        "\n",
        "yd = torch.from_numpy(dig_MNIST.label.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lybFj2Opb3yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(xd[7].view(28,28),cmap='Greys')\n",
        "ax.text(10,30,'Number {}'.format(yd[7]), bbox={'facecolor': 'white', 'pad': 10})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SS8v4nCQb3ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dsd = MyDataset(xd,yd,transform=tfms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mRV6hr_8b3yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_all = torch.utils.data.ConcatDataset((ds,dsd))\n",
        "dl_all = DataLoader(ds_all,batch_size=200,shuffle=True,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lRBj2AeOb3yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,accuracy = learn(net.to(device),dl_all,15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NuWmpVe6b3yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,accuracy = learn(net.to(device),dl_all,15,lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8-RtTPEEb3yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dig_MNIST.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6gjB8t3b3yx",
        "colab_type": "text"
      },
      "source": [
        "# 8. ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yrjXFOffb3yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = tv.models.resnet34(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8feiqAwDb3y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaptiveConcatPool2d(nn.Module): #This model concatenate Avg and Max pools in one Tensor \n",
        "    def __init__(self, sz=None):\n",
        "        super().__init__()\n",
        "        sz = sz or (1,1)\n",
        "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
        "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
        "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xFDP7mPpb3y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avgpool = nn.Sequential(\n",
        "                        AdaptiveConcatPool2d(1),\n",
        "                        nn.Flatten(),\n",
        "                        nn.BatchNorm1d(1024),\n",
        "                        nn.Dropout(p=0.25),\n",
        "                        nn.Linear(1024,512),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm1d(512),\n",
        "                        nn.Dropout(p=0.5))\n",
        "fc = nn.Linear(512,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjtOdfVZb3y4",
        "colab_type": "text"
      },
      "source": [
        "# Using Conv1d only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vQIPn-Rvb3y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Net1D().to(device)\n",
        "m.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iSayu84rb3y8",
        "colab_type": "code",
        "outputId": "4eb55536-6163-482e-8b26-65283f30c5a1",
        "colab": {}
      },
      "source": [
        "learn(m,50,dls,1e-1);learn(m,10,dl,lr=1e-1);learn(m,10,dl,lr=1e-2);learn(m,10,dl,lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: loss:0.06667916337028146 accuracy:99.6%\n",
            "2: loss:0.060050968546420336 accuracy:99.6%\n",
            "3: loss:0.04079471528530121 accuracy:99.8%\n",
            "4: loss:0.08514180267229676 accuracy:99.6%\n",
            "5: loss:0.10633922112174332 accuracy:99.8%\n",
            "10: loss:0.029716481221839786 accuracy:100.0%\n",
            "20: loss:0.08864672121126205 accuracy:99.6%\n",
            "30: loss:0.06150233279913664 accuracy:99.6%\n",
            "40: loss:0.06071928492747247 accuracy:99.8%\n",
            "50: loss:0.04234936251305044 accuracy:99.6%\n",
            "1: loss:12.19397168874275 accuracy:99.388%\n",
            "2: loss:8.95889827699284 accuracy:99.559%\n",
            "3: loss:6.713286598358536 accuracy:99.692%\n",
            "4: loss:4.511119167389552 accuracy:99.805%\n",
            "5: loss:5.5902711779745005 accuracy:99.751%\n",
            "10: loss:2.131090602470067 accuracy:99.907%\n",
            "1: loss:0.8798348905547755 accuracy:99.969%\n",
            "2: loss:0.46144167015290805 accuracy:99.99%\n",
            "3: loss:0.3602612484492056 accuracy:99.994%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jx4P1ypUb3y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(m.state_dict(),'conv1d_100.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FNoWWV90b3zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}